{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _params_models import rf_model_params\n",
    "from _ml_models import *\n",
    "from _plots import *\n",
    "from _util import *\n",
    "\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility\n",
    "functions and things that helped the use and modularity of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(dataset_name=\"sinusoid_8h\"):\n",
    "    source_data = dataset_name\n",
    "    if dataset_name == \"mix\":\n",
    "        source_data = \"mix_5h\"\n",
    "    if dataset_name == \"flashcrowd\":\n",
    "        source_data = \"flashcrowd_6h\"\n",
    "    if dataset_name == \"sinusoid\":\n",
    "        source_data = \"sinusoid_8h\"\n",
    "    data_log = pd.read_csv(f\"assets/data/log_INT_{source_data}.txt\", delimiter=\",\")\n",
    "    data_log.columns = data_log.columns.str.replace(\" \", \"\")\n",
    "    data_dash = pd.read_csv(f\"assets/data/dash_{source_data}.log\", sep=\",\")\n",
    "\n",
    "    return data_log, data_dash\n",
    "\n",
    "def remove_useless_attribute(dataset):\n",
    "    dataset.drop(columns=dataset.columns[dataset.nunique() == 1], inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def remove_outlier_IQR(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_final = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))]\n",
    "    return df_final\n",
    "\n",
    "def change_NaN_to_mean(dataset):\n",
    "    dataset = dataset.fillna(dataset.mean())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def normalization(X):\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X\n",
    "\n",
    "def merge_datasert(data_log, data_dash):\n",
    "    data_log = remove_useless_attribute(data_log)\n",
    "\n",
    "    data_dash['timestamp'] = data_dash['timestamp'].astype(str).str[:10].astype(int)\n",
    "    total = data_log.merge(data_dash, on=['timestamp', 'timestamp'], how='left')\n",
    "   \n",
    "    total = remove_outlier_IQR(total)\n",
    "    total = change_NaN_to_mean(total)\n",
    "    features = total.iloc[:,1:len(data_log.columns)].values\n",
    "    labels = total['framesDisplayedCalc'].values\n",
    "\n",
    "    features = normalization(features)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def visualize_results(feature_importances, feature_names):\n",
    "\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Features': feature_names,\n",
    "        'Importância': feature_importances\n",
    "    }).sort_values(by='Importância', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x='Importância', y='Features', data=feature_importances_df)\n",
    "    plt.title('Importância das Features')\n",
    "    plt.xlabel('Importância')\n",
    "    plt.ylabel('Features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for tranning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(y_true, y_pred):\n",
    "    nmae_value = mean_absolute_error(y_true, y_pred) / np.mean(y_true)\n",
    "    return nmae_value\n",
    "\n",
    "def default_random_forest_model(\n",
    "    features: pd.DataFrame, labels: pd.Series, model_params: rf_model_params\n",
    "):\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=model_params.test_size,\n",
    "        random_state=model_params.random_state,\n",
    "        shuffle=model_params.shuffle\n",
    "    )\n",
    "\n",
    "    X_train_scaled = X_train\n",
    "    X_validation_scaled = X_validation\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=model_params.n_estimators,\n",
    "        max_depth=model_params.max_depth,\n",
    "        min_samples_split=model_params.min_samples_split,\n",
    "        min_samples_leaf=model_params.min_samples_leaf,\n",
    "        bootstrap=model_params.bootstrap,\n",
    "        verbose=model_params.verbose,\n",
    "        max_features=model_params.max_features,\n",
    "        n_jobs=model_params.n_jobs,\n",
    "        random_state=model_params.random_state,\n",
    "    )\n",
    "\n",
    "    mae_scorer = make_scorer(nmae, greater_is_better=False)\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=model_params.n_splits,\n",
    "        shuffle=model_params.shuffle,\n",
    "    )\n",
    "\n",
    "    cross_val_scores = cross_val_score(\n",
    "        rf_model, X_train_scaled, y_train, cv=kf, scoring=mae_scorer\n",
    "    )\n",
    "\n",
    "    avg_cross_val_score = np.mean(cross_val_scores)\n",
    "\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    predictions = rf_model.predict(X_validation_scaled)\n",
    "    mae_rf = mean_absolute_error(y_validation, predictions)\n",
    "    nmae_rf = nmae(y_validation, predictions)\n",
    "\n",
    "    return mae_rf, nmae_rf, rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_sinusoid, data_dash_sinusoid = get_datasets('sinusoid')\n",
    "data_log_flashcrowd, data_dash_flashcrowd = get_datasets('flashcrowd')\n",
    "data_log_mix, data_dash_mix = get_datasets('mix')\n",
    "data_log = pd.concat([data_log_sinusoid, data_log_flashcrowd, data_log_mix])\n",
    "data_dash = pd.concat([data_dash_sinusoid, data_dash_flashcrowd, data_dash_mix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = remove_useless_attribute(data_log)\n",
    "aux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sinusoid, labels_sinusoid = merge_dataset(data_log_sinusoid, data_dash_sinusoid)\n",
    "features_flashcrowd, labels_flashcrowd = merge_dataset(data_log_flashcrowd, data_dash_flashcrowd)\n",
    "features_mix, labels_mix = merge_dataset(data_log_mix, data_dash_mix)\n",
    "features_total, labels_total = merge_dataset(data_log, data_dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features_sinusoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_print_model(features, labels, best_params, label):\n",
    "    start_time = time.time()\n",
    "    mae, nmae, model = default_random_forest_model(features, labels, best_params)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    minutes = int(elapsed_time // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "\n",
    "    print(f\"{label} -> MAE = {mae}, NMAE = {nmae * 100:.2f}%, Tempo de treino: {minutes} minutos e {seconds} segundos\")\n",
    "    return mae, nmae, model\n",
    "\n",
    "best_params = rf_model_params(\n",
    "    n_estimators=90,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    max_depth=44,\n",
    "    bootstrap=True,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    "    test_size=0.2,\n",
    "    verbose = 0,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "mae_sinusoid, nmae_sinusoid, model_sinusoid = evaluate_and_print_model(features_sinusoid, labels_sinusoid, best_params, \"Sinusoid\")\n",
    "mae_flashcrowd, nmae_flashcrowd, model_flashcrowd = evaluate_and_print_model(features_flashcrowd, labels_flashcrowd, best_params, \"Flashcrowd\")\n",
    "mae_mix, nmae_mix, model_mix = evaluate_and_print_model(features_mix, labels_mix, best_params, \"Mix\")\n",
    "mae_total, nmae_total, model_total = evaluate_and_print_model(features, labels, best_params, \"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_comparison(start_graph, end_graph, labels_list, predictions_list, model_name):\n",
    "    print(len(labels_list))\n",
    "    print(len(predictions_list))\n",
    "    datasets_info = [\n",
    "        ('Sinusoid', labels_list[0][start_graph:end_graph], predictions_list[0][start_graph:end_graph]),\n",
    "        ('Flashcrowd', labels_list[1][start_graph:end_graph], predictions_list[1][start_graph:end_graph]),\n",
    "        ('Mix', labels_list[2][start_graph:end_graph], predictions_list[2][start_graph:end_graph]),\n",
    "        ('Total', labels_list[3][start_graph:end_graph], predictions_list[3][start_graph:end_graph])\n",
    "    ]\n",
    "\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(16, 16), constrained_layout=True)\n",
    "    t = np.arange(start_graph, end_graph)\n",
    "\n",
    "    ax1.plot(t, datasets_info[0][1], label='Sinusoid Labels', color='blue')\n",
    "    ax1.plot(t, datasets_info[0][2], label='Sinusoid Predictions', color='orange')\n",
    "    ax1.set_title('Sinusoid: Labels vs Predictions')\n",
    "    ax1.set_xlabel('Índice')\n",
    "    ax1.set_ylabel('Valor')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(t, datasets_info[1][1], label='Flashcrowd Labels', color='green')\n",
    "    ax2.plot(t, datasets_info[1][2], label='Flashcrowd Predictions', color='red')\n",
    "    ax2.set_title('Flashcrowd: Labels vs Predictions')\n",
    "    ax2.set_xlabel('Índice')\n",
    "    ax2.set_ylabel('Valor')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "\n",
    "    ax3.plot(t, datasets_info[2][1], label='Mix Labels', color='purple')\n",
    "    ax3.plot(t, datasets_info[2][2], label='Mix Predictions', color='green')\n",
    "    ax3.set_title('Mix: Labels vs Predictions')\n",
    "    ax3.set_xlabel('Índice')\n",
    "    ax3.set_ylabel('Valor')\n",
    "    ax3.grid(True)\n",
    "    ax3.legend()\n",
    "\n",
    "    ax4.plot(t, datasets_info[3][1], label='Total Labels', color='blue')\n",
    "    ax4.plot(t, datasets_info[3][2], label='Total Predictions', color='yellow')\n",
    "    ax4.set_title('Total: Labels vs Predictions')\n",
    "    ax4.set_xlabel('Índice')\n",
    "    ax4.set_ylabel('Valor')\n",
    "    ax4.grid(True)\n",
    "    ax4.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Sinusoid', 'Flashcrowd', 'Mix', 'Total']\n",
    "model_names = ['Sinusoid', 'Flashcrowd', 'Mix', 'Total']\n",
    "models = [model_sinusoid, model_flashcrowd, model_mix, model_total]\n",
    "\n",
    "features_list = [features_sinusoid, features_flashcrowd, features_mix, features_total]\n",
    "labels_list = [labels_sinusoid, labels_flashcrowd, labels_mix, labels_total]\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    predictions = [model.predict(features) for features in features_list]\n",
    "    nmae_values = [nmae(labels, pred) for labels, pred in zip(labels_list, predictions)]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(datasets, nmae_values, color=['skyblue', 'lightgreen', 'salmon', 'yellow'])\n",
    "    plt.title(f'NMAE para cada Dataset usando o modelo treinado com {model_name}')\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('NMAE')\n",
    "    plt.ylim(0, max(nmae_values) * 1.2)\n",
    "\n",
    "    for bar, value in zip(bars, nmae_values):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2, \n",
    "            bar.get_height(),               \n",
    "            f'{value:.2f}%',               \n",
    "            ha='center', va='bottom'            \n",
    "        )\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "    plt.show()  \n",
    "\n",
    "    plot_predictions_comparison(\n",
    "        start_graph=100, \n",
    "        end_graph=20200, \n",
    "        labels_list=[labels_sinusoid, labels_flashcrowd, labels_mix, labels_total],\n",
    "        predictions_list=predictions,\n",
    "        model_name=model_name\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
