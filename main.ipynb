{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _params_models import rf_model_params\n",
    "from _ml_models import *\n",
    "from _plots import *\n",
    "from _util import *\n",
    "\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility\n",
    "functions and things that helped the use and modularity of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(dataset_name=\"sinusoid_8h\"):\n",
    "    source_data = dataset_name\n",
    "    if dataset_name == \"mix\":\n",
    "        source_data = \"mix_5h\"\n",
    "    if dataset_name == \"flashcrowd\":\n",
    "        source_data = \"flashcrowd_6h\"\n",
    "    if dataset_name == \"sinusoid\":\n",
    "        source_data = \"sinusoid_8h\"\n",
    "    data_log = pd.read_csv(f\"assets/data/log_INT_{source_data}.txt\", delimiter=\",\")\n",
    "    data_log.columns = data_log.columns.str.replace(\" \", \"\")\n",
    "    data_dash = pd.read_csv(f\"assets/data/dash_{source_data}.log\", sep=\",\")\n",
    "\n",
    "    return data_log, data_dash\n",
    "\n",
    "def remove_useless_attribute(dataset):\n",
    "    dataset.drop(columns=dataset.columns[dataset.nunique() == 1], inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def remove_outlier_IQR(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_final = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))]\n",
    "    return df_final\n",
    "\n",
    "def change_NaN_to_mean(dataset):\n",
    "    dataset = dataset.fillna(dataset.mean())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def normalization(X):\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X\n",
    "\n",
    "def merge_datasert(data_log, data_dash):\n",
    "    data_log = remove_useless_attribute(data_log)\n",
    "\n",
    "    data_dash['timestamp'] = data_dash['timestamp'].astype(str).str[:10].astype(int)\n",
    "    total = data_log.merge(data_dash, on=['timestamp', 'timestamp'], how='left')\n",
    "   \n",
    "    total = remove_outlier_IQR(total)\n",
    "    total = change_NaN_to_mean(total)\n",
    "    features = total.iloc[:,1:len(data_log.columns)].values\n",
    "    labels = total['framesDisplayedCalc'].values\n",
    "\n",
    "    features = normalization(features)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def visualize_results(feature_importances, feature_names):\n",
    "\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Features': feature_names,\n",
    "        'Importância': feature_importances\n",
    "    }).sort_values(by='Importância', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x='Importância', y='Features', data=feature_importances_df)\n",
    "    plt.title('Importância das Features')\n",
    "    plt.xlabel('Importância')\n",
    "    plt.ylabel('Features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for tranning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(y_true, y_pred):\n",
    "    nmae_value = mean_absolute_error(y_true, y_pred) / np.mean(y_true)\n",
    "    return nmae_value\n",
    "\n",
    "def default_random_forest_model(\n",
    "    features: pd.DataFrame, labels: pd.Series, model_params: rf_model_params\n",
    "):\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=model_params.test_size,\n",
    "        random_state=model_params.random_state,\n",
    "        shuffle=model_params.shuffle\n",
    "    )\n",
    "\n",
    "    X_train_scaled = X_train\n",
    "    X_validation_scaled = X_validation\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=model_params.n_estimators,\n",
    "        max_depth=model_params.max_depth,\n",
    "        min_samples_split=model_params.min_samples_split,\n",
    "        min_samples_leaf=model_params.min_samples_leaf,\n",
    "        bootstrap=model_params.bootstrap,\n",
    "        verbose=model_params.verbose,\n",
    "        max_features=model_params.max_features,\n",
    "        n_jobs=model_params.n_jobs,\n",
    "        random_state=model_params.random_state,\n",
    "    )\n",
    "\n",
    "    mae_scorer = make_scorer(nmae, greater_is_better=False)\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=model_params.n_splits,\n",
    "        shuffle=model_params.shuffle,\n",
    "    )\n",
    "\n",
    "    cross_val_scores = cross_val_score(\n",
    "        rf_model, X_train_scaled, y_train, cv=kf, scoring=mae_scorer\n",
    "    )\n",
    "\n",
    "    avg_cross_val_score = np.mean(cross_val_scores)\n",
    "\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    predictions = rf_model.predict(X_validation_scaled)\n",
    "    mae_rf = mean_absolute_error(y_validation, predictions)\n",
    "    nmae_rf = nmae(y_validation, predictions)\n",
    "\n",
    "    return mae_rf, nmae_rf, rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_sinusoid, data_dash_sinusoid = get_datasets('sinusoid')\n",
    "data_log_flashcrowd, data_dash_flashcrowd = get_datasets('flashcrowd')\n",
    "data_log_mix, data_dash_mix = get_datasets('mix')\n",
    "data_log = pd.concat([data_log_sinusoid, data_log_flashcrowd, data_log_mix])\n",
    "data_dash = pd.concat([data_dash_sinusoid, data_dash_flashcrowd, data_dash_mix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(verbose=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Parallel' object has no attribute '_pre_dispatch_amount'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:189\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    187\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     11\u001b[39m model = RandomForestRegressor(\n\u001b[32m     12\u001b[39m     n_estimators = \u001b[32m100\u001b[39m,\n\u001b[32m     13\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m predict = model.predict(X_validation)\n\u001b[32m     20\u001b[39m mae = mean_absolute_error(y_validation, predict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/joblib/parallel.py:1928\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28mself\u001b[39m._iterating = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1927\u001b[39m \u001b[38;5;28mself\u001b[39m._original_iterator = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprint_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/mindspore/.env/lib/python3.12/site-packages/joblib/parallel.py:1617\u001b[39m, in \u001b[36mParallel.print_progress\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1613\u001b[39m \u001b[38;5;66;03m# We always display the first loop\u001b[39;00m\n\u001b[32m   1614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index != \u001b[32m0\u001b[39m:\n\u001b[32m   1615\u001b[39m     \u001b[38;5;66;03m# Display depending on the number of remaining items\u001b[39;00m\n\u001b[32m   1616\u001b[39m     \u001b[38;5;66;03m# A message as soon as we finish dispatching, cursor is 0\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1617\u001b[39m     cursor = total_tasks - index + \u001b[32m1\u001b[39m - \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pre_dispatch_amount\u001b[49m\n\u001b[32m   1618\u001b[39m     frequency = (total_tasks // \u001b[38;5;28mself\u001b[39m.verbose) + \u001b[32m1\u001b[39m\n\u001b[32m   1619\u001b[39m     is_last_item = index + \u001b[32m1\u001b[39m == total_tasks\n",
      "\u001b[31mAttributeError\u001b[39m: 'Parallel' object has no attribute '_pre_dispatch_amount'"
     ]
    }
   ],
   "source": [
    "remove_useless_attribute(data_log_mix)\n",
    "features, labels = merge_datasert(data_log_mix, data_dash_mix)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=0.8,\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators = 100,\n",
    "    verbose=True\n",
    ")\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_validation)\n",
    "\n",
    "mae = mean_absolute_error(y_validation, predict)\n",
    "\n",
    "print(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sinusoid, labels_sinusoid = merge_dataset(data_log_sinusoid, data_dash_sinusoid)\n",
    "features_flashcrowd, labels_flashcrowd = merge_dataset(data_log_flashcrowd, data_dash_flashcrowd)\n",
    "features_mix, labels_mix = merge_dataset(data_log_mix, data_dash_mix)\n",
    "features_total, labels_total = merge_dataset(data_log, data_dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features_sinusoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6134975800777552\n",
      "0.7863148323822956\n",
      "0.38619131376151156\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_print_model(features, labels, best_params, label):\n",
    "    start_time = time.time()\n",
    "    mae, nmae, model = default_random_forest_model(features, labels, best_params)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    minutes = int(elapsed_time // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "\n",
    "    print(f\"{label} -> MAE = {mae}, NMAE = {nmae * 100:.2f}%, Tempo de treino: {minutes} minutos e {seconds} segundos\")\n",
    "    return mae, nmae, model\n",
    "\n",
    "best_params = rf_model_params(\n",
    "    n_estimators=60,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    max_depth=44,\n",
    "    bootstrap=True,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    "    test_size=0.2,\n",
    "    verbose = 0,\n",
    "    n_jobs=6\n",
    ")\n",
    "\n",
    "# mae_sinusoid, nmae_sinusoid, model_sinusoid = evaluate_and_print_model(features_sinusoid, labels_sinusoid, best_params, \"Sinusoid\")\n",
    "print(nmae_sinusoid)\n",
    "# mae_flashcrowd, nmae_flashcrowd, model_flashcrowd = evaluate_and_print_model(features_flashcrowd, labels_flashcrowd, best_params, \"Flashcrowd\")\n",
    "print(nmae_flashcrowd)\n",
    "# mae_mix, nmae_mix, model_mix = evaluate_and_print_model(features_mix, labels_mix, best_params, \"Mix\")\n",
    "print(nmae_mix)\n",
    "# mae_total, nmae_total, model_total = evaluate_and_print_model(features, labels, best_params, \"Total\")\n",
    "# print(name_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_comparison(start_graph, end_graph, labels_list, predictions_list, model_name):\n",
    "    print(len(labels_list))\n",
    "    print(len(predictions_list))\n",
    "    datasets_info = [\n",
    "        ('Sinusoid', labels_list[0][start_graph:end_graph], predictions_list[0][start_graph:end_graph]),\n",
    "        ('Flashcrowd', labels_list[1][start_graph:end_graph], predictions_list[1][start_graph:end_graph]),\n",
    "        ('Mix', labels_list[2][start_graph:end_graph], predictions_list[2][start_graph:end_graph]),\n",
    "        ('Total', labels_list[3][start_graph:end_graph], predictions_list[3][start_graph:end_graph])\n",
    "    ]\n",
    "\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(16, 16), constrained_layout=True)\n",
    "    t = np.arange(start_graph, end_graph)\n",
    "\n",
    "    ax1.plot(t, datasets_info[0][1], label='Sinusoid Labels', color='blue')\n",
    "    ax1.plot(t, datasets_info[0][2], label='Sinusoid Predictions', color='orange')\n",
    "    ax1.set_title('Sinusoid: Labels vs Predictions')\n",
    "    ax1.set_xlabel('Índice')\n",
    "    ax1.set_ylabel('Valor')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(t, datasets_info[1][1], label='Flashcrowd Labels', color='green')\n",
    "    ax2.plot(t, datasets_info[1][2], label='Flashcrowd Predictions', color='red')\n",
    "    ax2.set_title('Flashcrowd: Labels vs Predictions')\n",
    "    ax2.set_xlabel('Índice')\n",
    "    ax2.set_ylabel('Valor')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "\n",
    "    ax3.plot(t, datasets_info[2][1], label='Mix Labels', color='purple')\n",
    "    ax3.plot(t, datasets_info[2][2], label='Mix Predictions', color='green')\n",
    "    ax3.set_title('Mix: Labels vs Predictions')\n",
    "    ax3.set_xlabel('Índice')\n",
    "    ax3.set_ylabel('Valor')\n",
    "    ax3.grid(True)\n",
    "    ax3.legend()\n",
    "\n",
    "    ax4.plot(t, datasets_info[3][1], label='Total Labels', color='blue')\n",
    "    ax4.plot(t, datasets_info[3][2], label='Total Predictions', color='yellow')\n",
    "    ax4.set_title('Total: Labels vs Predictions')\n",
    "    ax4.set_xlabel('Índice')\n",
    "    ax4.set_ylabel('Valor')\n",
    "    ax4.grid(True)\n",
    "    ax4.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Sinusoid', 'Flashcrowd', 'Mix', 'Total']\n",
    "model_names = ['Sinusoid', 'Flashcrowd', 'Mix', 'Total']\n",
    "models = [model_sinusoid, model_flashcrowd, model_mix, model_total]\n",
    "\n",
    "features_list = [features_sinusoid, features_flashcrowd, features_mix, features_total]\n",
    "labels_list = [labels_sinusoid, labels_flashcrowd, labels_mix, labels_total]\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    predictions = [model.predict(features) for features in features_list]\n",
    "    nmae_values = [nmae(labels, pred) for labels, pred in zip(labels_list, predictions)]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(datasets, nmae_values, color=['skyblue', 'lightgreen', 'salmon', 'yellow'])\n",
    "    plt.title(f'NMAE para cada Dataset usando o modelo treinado com {model_name}')\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('NMAE')\n",
    "    plt.ylim(0, max(nmae_values) * 1.2)\n",
    "\n",
    "    for bar, value in zip(bars, nmae_values):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2, \n",
    "            bar.get_height(),               \n",
    "            f'{value:.2f}%',               \n",
    "            ha='center', va='bottom'            \n",
    "        )\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "    plt.show()  \n",
    "\n",
    "    plot_predictions_comparison(\n",
    "        start_graph=100, \n",
    "        end_graph=20200, \n",
    "        labels_list=[labels_sinusoid, labels_flashcrowd, labels_mix, labels_total],\n",
    "        predictions_list=predictions,\n",
    "        model_name=model_name\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
