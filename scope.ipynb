{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from _util import *\n",
    "from _params_models import rf_model_params\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import sympy as sp\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = [1000, 1020, 1035, 1060, 1078, 1105]  \n",
    "delays = np.diff(timestamps)\n",
    "jitter = np.abs(np.diff(delays))\n",
    "print(\"Tempos de chegada dos pacotes:\", timestamps)\n",
    "print(\"Atrasos entre pacotes consecutivos:\", delays)\n",
    "print(\"Jitter entre pacotes consecutivos:\", jitter)\n",
    "print(\"Jitter médio:\", np.mean(jitter))\n",
    "print(\"Jitter máximo:\", np.max(jitter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando dados\n",
    "sleep1_dash = pd.read_csv(\"assets/data/part2/sleep_1/data_dash.log\", delimiter=\",\", header=None, skiprows=1, on_bad_lines='skip')\n",
    "sleep10_dash = pd.read_csv(\"assets/data/part2/sleep_10/data_dash.log\", delimiter=\",\", header=None, skiprows=1, on_bad_lines='skip')\n",
    "sleep05_dash = pd.read_csv(\"assets/data/part2/sleep_05/data_dash.log\", delimiter=\",\", header=None, skiprows=1, on_bad_lines='skip')\n",
    "sleep0_dash = pd.read_csv(\"assets/data/part2/sleep_0/data_dash.log\", delimiter=\",\", header=None, skiprows=1, on_bad_lines='skip')\n",
    "\n",
    "sleep1_int = pd.read_csv(\"assets/data/part2/sleep_1/data_int_.csv\", delimiter=\",\", header=None, skiprows=1, on_bad_lines='skip')\n",
    "sleep10_int = pd.read_csv(\"assets/data/part2/sleep_10/data_int_.csv\", delimiter=\",\", header=None, skiprows=1, on_bad_lines='skip')\n",
    "sleep05_int = pd.read_csv(\"assets/data/part2/sleep_05/data_int_.csv\", delimiter=\",\",  header=None, skiprows=1, on_bad_lines='skip')\n",
    "sleep0_int = pd.read_csv(\"assets/data/part2/sleep_0/data_int_.csv\", delimiter=\",\",  header=None, skiprows=1, on_bad_lines='skip')\n",
    "\n",
    "sleep1_int = remove_useless_attribute(sleep1_int).reset_index(drop=True)\n",
    "sleep10_int = remove_useless_attribute(sleep10_int).reset_index(drop=True)\n",
    "sleep05_int = remove_useless_attribute(sleep05_int).reset_index(drop=True)\n",
    "sleep0_int = remove_useless_attribute(sleep0_int).reset_index(drop=True)\n",
    "\n",
    "columns_name_int = [\"timestamp\",\"ingress_global_timestamp3\",\"egress_global_timestamp3\",\"enq_timestamp3\",\"enq_qdepth3\",\"deq_timedelta3\",\"deq_qdepth3\",\"ingress_global_timestamp2\",\t\"egress_global_timestamp2\",\t\"enq_timestamp2\",\t\"enq_qdepth2\",\t\"deq_timedelta2\",\t\"deq_qdepth2\",\t\"ingress_global_timestamp1\",\t\"egress_global_timestamp1\",\t\"enq_timestamp1\",\t\"enq_qdepth1\"\t,\"deq_timedelta1\",\t\"deq_qdepth1\"]\n",
    "columns_name_dash = [\"timestamp\",\"inputBitrate\",\"demuxBitrate\",\"demuxCorrupted\",\"demuxDiscontinuity\",\"sendBitrate\",\"framesDisplayed\",\"playedAudioBuffers\",\"decodedVideo\",\"decodedAudio\",\"framesDisplayedAux\",\"playedAudioBuffersAux\",\"decodedVideoAux\",\"decodedAudioAux\",\"framesDisplayedCalc\",\"playedAudioBuffersCalc\",\"decodedVideoCalc\",\"decodedAudioCalc\"]\n",
    "\n",
    "sleep1_int.columns = columns_name_int\n",
    "sleep10_int.columns = columns_name_int\n",
    "sleep05_int.columns = columns_name_int\n",
    "sleep0_int.columns = columns_name_int\n",
    "\n",
    "sleep1_dash.columns = columns_name_dash\n",
    "sleep10_dash.columns = columns_name_dash\n",
    "sleep05_dash.columns = columns_name_dash\n",
    "sleep0_dash.columns = columns_name_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep1_features, sleep1_labels = merge_dataset(sleep1_int, sleep1_dash)\n",
    "sleep10_features, sleep10_labels = merge_dataset(sleep10_int, sleep10_dash)\n",
    "sleep05_features, sleep05_labels = merge_dataset(sleep05_int, sleep05_dash)\n",
    "sleep0_features, sleep0_labels = merge_dataset(sleep0_int, sleep0_dash)\n",
    "\n",
    "sleep05_features_df = pd.DataFrame(sleep1_features)\n",
    "sleep1_features_df = pd.DataFrame(sleep1_features)\n",
    "sleep10_features_df = pd.DataFrame(sleep10_features)\n",
    "\n",
    "switches05 = [sleep05_features_df.iloc[:, i:i+6] for i in range(0, sleep05_features_df.shape[1], 6)]\n",
    "switches1 = [sleep1_features_df.iloc[:, i:i+6] for i in range(0, sleep1_features_df.shape[1], 6)]\n",
    "switches10 = [sleep10_features_df.iloc[:, i:i+6] for i in range(0, sleep10_features_df.shape[1], 6)]\n",
    "\n",
    "sleep05_switch1 = switches05[0]\n",
    "sleep05_switch2 = switches05[1]\n",
    "sleep05_switch3 = switches05[2]\n",
    "\n",
    "sleep1_switch1 = switches1[0]\n",
    "sleep1_switch2 = switches1[1]\n",
    "sleep1_switch3 = switches1[2]\n",
    "\n",
    "sleep10_switch1 = switches10[0]\n",
    "sleep10_switch2 = switches10[1]\n",
    "sleep10_switch3 = switches10[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(features, labels, best_params, sleep_duration):\n",
    "    start_time = time.time()\n",
    "    mae, nmae, model = default_random_forest_model(features, labels, best_params)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    minutes = int(elapsed_time // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    milliseconds = int((elapsed_time % 1) * 1000)\n",
    "    print(f\"Sleep {sleep_duration} -> MAE = {mae:.5f}, NMAE = {nmae * 100:.2f}%, Tempo de treino: {minutes} minutos/{seconds} segundos/ {milliseconds} milissegundos\")\n",
    "    return mae, nmae, model\n",
    "\n",
    "best_params = rf_model_params(\n",
    "    n_estimators=90,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    max_depth=44,\n",
    "    bootstrap=True,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    "    test_size=0.2,\n",
    "    verbose = 0,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "mae_sleep0, nmae_sleep0, model_sleep0 = evaluate_model(sleep0_features, sleep0_labels, best_params, 0)\n",
    "mae_sleep05, nmae_sleep05, model_sleep05 = evaluate_model(sleep05_features, sleep05_labels, best_params, 0.5)\n",
    "mae_sleep1, nmae_sleep1, model_sleep1 = evaluate_model(sleep1_features, sleep1_labels, best_params, 1)\n",
    "mae_sleep10, nmae_sleep10, model_sleep10 = evaluate_model(sleep10_features, sleep10_labels, best_params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['05s1', '05s2', '05s3']\n",
    "model_names = ['05s1', '05s2', '05s3']\n",
    "models = [model_05s1, model_05s2, model_05s3]\n",
    "\n",
    "features_list = [sleep05_switch1, sleep05_switch2, sleep05_switch3]\n",
    "labels_list = [sleep1_labels, sleep1_labels, sleep1_labels]\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    predictions = [model.predict(features) for features in features_list]\n",
    "    nmae_values = [nmae(labels, pred) for labels, pred in zip(labels_list, predictions)]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(datasets, nmae_values, color=['skyblue', 'lightgreen', 'salmon', 'yellow'])\n",
    "    plt.title(f'NMAE para cada Dataset usando o modelo treinado com {model_name}')\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('NMAE')\n",
    "    plt.ylim(0, max(nmae_values) * 1.2)\n",
    "\n",
    "    for bar, value in zip(bars, nmae_values):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2, \n",
    "            bar.get_height(),               \n",
    "            f'{value:.4f}%',               \n",
    "            ha='center', va='bottom'            \n",
    "        )\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "    plt.show()  \n",
    "\n",
    "    plot_predictions_comparison(\n",
    "        start_graph=100, \n",
    "        end_graph=500, \n",
    "        labels_list=labels_list,\n",
    "        predictions_list=predictions,\n",
    "        model_name=model_name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_comparison(start_graph, end_graph, labels_list, predictions_list, model_name):\n",
    "    print(len(labels_list))\n",
    "    print(len(predictions_list))\n",
    "    datasets_info = [\n",
    "        ('Switch1', labels_list[0][start_graph:end_graph], predictions_list[0][start_graph:end_graph]),\n",
    "        ('SWitch2', labels_list[1][start_graph:end_graph], predictions_list[1][start_graph:end_graph]),\n",
    "        ('SWitch3', labels_list[2][start_graph:end_graph], predictions_list[2][start_graph:end_graph]),\n",
    "    ]\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12), constrained_layout=True)\n",
    "    t = np.arange(start_graph, end_graph)\n",
    "\n",
    "    ax1.plot(t, datasets_info[0][1], label='Sinusoid Labels', color='blue')\n",
    "    ax1.plot(t, datasets_info[0][2], label='Sinusoid Predictions', color='orange')\n",
    "    ax1.set_title('Sinusoid: Labels vs Predictions')\n",
    "    ax1.set_xlabel('Índice')\n",
    "    ax1.set_ylabel('Valor')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(t, datasets_info[1][1], label='Flashcrowd Labels', color='green')\n",
    "    ax2.plot(t, datasets_info[1][2], label='Flashcrowd Predictions', color='red')\n",
    "    ax2.set_title('Flashcrowd: Labels vs Predictions')\n",
    "    ax2.set_xlabel('Índice')\n",
    "    ax2.set_ylabel('Valor')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "\n",
    "    ax3.plot(t, datasets_info[2][1], label='Mix Labels', color='purple')\n",
    "    ax3.plot(t, datasets_info[2][2], label='Mix Predictions', color='green')\n",
    "    ax3.set_title('Mix: Labels vs Predictions')\n",
    "    ax3.set_xlabel('Índice')\n",
    "    ax3.set_ylabel('Valor')\n",
    "    ax3.grid(True)\n",
    "    ax3.legend()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
